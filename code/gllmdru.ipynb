{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":171475,"sourceType":"datasetVersion","datasetId":76158}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport time\nfrom torch.utils.data import Dataset\nfrom transformers import (AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments,\n                          TrainerCallback, EarlyStoppingCallback, AdamW)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom torch.nn import CrossEntropyLoss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:14:32.377647Z","iopub.execute_input":"2025-04-03T14:14:32.377934Z","iopub.status.idle":"2025-04-03T14:14:32.399272Z","shell.execute_reply.started":"2025-04-03T14:14:32.377913Z","shell.execute_reply":"2025-04-03T14:14:32.398488Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Custom Callback for Epoch Timing\nclass EpochTimeCallback(TrainerCallback):\n    \"\"\" Custom callback to print epoch training status with time tracking. \"\"\"\n    def __init__(self):\n        self.epoch_start_time = None\n\n    def on_epoch_begin(self, args, state, control, **kwargs):\n        self.epoch_start_time = time.time()\n        print(f\"\\nðŸŸ¢ Epoch {int(state.epoch) + 1}/{args.num_train_epochs} started...\")\n\n    def on_epoch_end(self, args, state, control, **kwargs):\n        elapsed_time = time.time() - self.epoch_start_time\n        print(f\"âœ… Epoch {int(state.epoch) + 1} completed in {elapsed_time:.2f} seconds.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:14:32.400140Z","iopub.execute_input":"2025-04-03T14:14:32.400417Z","iopub.status.idle":"2025-04-03T14:14:32.417655Z","shell.execute_reply.started":"2025-04-03T14:14:32.400386Z","shell.execute_reply":"2025-04-03T14:14:32.416926Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load Data\nprint(\"ðŸš€ Loading data...\")\ndf = pd.read_csv('../input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv')\ntest = pd.read_csv('../input/kuc-hackathon-winter-2018/drugsComTest_raw.csv')\ndata = pd.concat([df, test])\nprint(\"âœ… Data loaded successfully!\")\n\n# Label sentiment based on ratings\nprint(\"ðŸ“ Labeling sentiment...\")\ndata.loc[data['rating'] >= 5, 'Review_Sentiment'] = 1\ndata.loc[data['rating'] < 5, 'Review_Sentiment'] = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:14:32.418504Z","iopub.execute_input":"2025-04-03T14:14:32.418774Z","iopub.status.idle":"2025-04-03T14:14:33.634501Z","shell.execute_reply.started":"2025-04-03T14:14:32.418747Z","shell.execute_reply":"2025-04-03T14:14:33.633614Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Loading data...\nâœ… Data loaded successfully!\nðŸ“ Labeling sentiment...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Handle missing values\ndata = data.dropna(subset=['review'])\nprint(f\"ðŸ” Data cleaned! Remaining samples: {len(data)}\")\n\n# Train-test split\nprint(\"âœ‚ Splitting data into training and validation sets...\")\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    data['review'].tolist(), data['Review_Sentiment'].tolist(), test_size=0.2, random_state=42, stratify=data['Review_Sentiment']\n)\nprint(f\"âœ… Data split: {len(train_texts)} training samples, {len(val_texts)} validation samples.\")\n\n# Load BioBERT tokenizer\nprint(\"ðŸ”„ Loading BioBERT tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\nprint(\"âœ… Tokenizer loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:14:33.635310Z","iopub.execute_input":"2025-04-03T14:14:33.635562Z","iopub.status.idle":"2025-04-03T14:14:35.036270Z","shell.execute_reply.started":"2025-04-03T14:14:33.635541Z","shell.execute_reply":"2025-04-03T14:14:35.035465Z"}},"outputs":[{"name":"stdout","text":"ðŸ” Data cleaned! Remaining samples: 215063\nâœ‚ Splitting data into training and validation sets...\nâœ… Data split: 172050 training samples, 43013 validation samples.\nðŸ”„ Loading BioBERT tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"290db0b498104ae78f17e709c26c2a19"}},"metadata":{}},{"name":"stdout","text":"âœ… Tokenizer loaded!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Tokenize data\nprint(\"âŒ› Tokenizing training and validation data...\")\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)  # Reduced max_length for efficiency\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=256)\nprint(\"âœ… Tokenization complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:14:41.595641Z","iopub.execute_input":"2025-04-03T14:14:41.596001Z","iopub.status.idle":"2025-04-03T14:15:22.322086Z","shell.execute_reply.started":"2025-04-03T14:14:41.595972Z","shell.execute_reply":"2025-04-03T14:15:22.321155Z"}},"outputs":[{"name":"stdout","text":"âŒ› Tokenizing training and validation data...\nâœ… Tokenization complete!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Convert to PyTorch Dataset\nclass DrugReviewDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)  # Fix: Use long dtype for CrossEntropyLoss\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:15:22.323198Z","iopub.execute_input":"2025-04-03T14:15:22.323447Z","iopub.status.idle":"2025-04-03T14:15:22.328248Z","shell.execute_reply.started":"2025-04-03T14:15:22.323426Z","shell.execute_reply":"2025-04-03T14:15:22.327312Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(\"ðŸ“¦ Creating dataset class...\")\ntrain_dataset = DrugReviewDataset(train_encodings, train_labels)\nval_dataset = DrugReviewDataset(val_encodings, val_labels)\nprint(f\"ðŸ“Š Training dataset: {len(train_dataset)} samples, Validation dataset: {len(val_dataset)} samples.\")\n\n# Load BioBERT model\nprint(\"ðŸ§  Loading BioBERT model for sequence classification...\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=2)\nprint(\"âœ… Model loaded!\")\n\n# Compute class weights for imbalanced dataset\nprint(\"âš– Computing class weights...\")\nclass_counts = np.bincount(train_labels)\nweights = torch.tensor([1.0 / class_counts[0], 1.0 / class_counts[1]], dtype=torch.float32).to(model.device)\nloss_fn = CrossEntropyLoss(weight=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:14.243569Z","iopub.execute_input":"2025-04-03T14:16:14.243935Z","iopub.status.idle":"2025-04-03T14:16:17.317978Z","shell.execute_reply.started":"2025-04-03T14:16:14.243906Z","shell.execute_reply":"2025-04-03T14:16:17.316920Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¦ Creating dataset class...\nðŸ“Š Training dataset: 172050 samples, Validation dataset: 43013 samples.\nðŸ§  Loading BioBERT model for sequence classification...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"996e4819128e43b6aae4b31cc0144adc"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Model loaded!\nâš– Computing class weights...\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Use AdamW optimizer with custom learning rate\n\noptimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)  # Lower LR and weight decay for better generalization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:28.253147Z","iopub.execute_input":"2025-04-03T14:16:28.253458Z","iopub.status.idle":"2025-04-03T14:16:28.262768Z","shell.execute_reply.started":"2025-04-03T14:16:28.253433Z","shell.execute_reply":"2025-04-03T14:16:28.261989Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=1)  # Convert logits to class predictions\n    accuracy = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:30.777890Z","iopub.execute_input":"2025-04-03T14:16:30.778180Z","iopub.status.idle":"2025-04-03T14:16:30.782668Z","shell.execute_reply.started":"2025-04-03T14:16:30.778161Z","shell.execute_reply":"2025-04-03T14:16:30.781885Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Define training arguments\nprint(\"âš™ Setting up training arguments...\")\ntraining_args = TrainingArguments(\n    output_dir=\"./biobert_results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=3,  # Keep only 3 best checkpoints\n    load_best_model_at_end=True,\n    per_device_train_batch_size=16,  # Increased batch size\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,  # Increased epochs from 3 to 5\n    gradient_accumulation_steps=2,  # Helps stabilize training\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\",  # Disable W&B logs\n    fp16=True,  # Enables mixed-precision training\n    weight_decay=0.01,\n    learning_rate=2e-5,\n    warmup_ratio=0.1,  # Helps with convergence\n    metric_for_best_model=\"accuracy\"\n)\nprint(\"âœ… Training arguments set!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:33.683170Z","iopub.execute_input":"2025-04-03T14:16:33.683472Z","iopub.status.idle":"2025-04-03T14:16:33.806543Z","shell.execute_reply.started":"2025-04-03T14:16:33.683450Z","shell.execute_reply":"2025-04-03T14:16:33.805647Z"}},"outputs":[{"name":"stdout","text":"âš™ Setting up training arguments...\nâœ… Training arguments set!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Define Trainer with Early Stopping\nprint(\"ðŸ“¢ Initializing Trainer with live tracking...\")\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, None),\n    callbacks=[EpochTimeCallback(), EarlyStoppingCallback(early_stopping_patience=2)]  # Early stopping prevents overfitting\n)\nprint(\"âœ… Trainer initialized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:38.649952Z","iopub.execute_input":"2025-04-03T14:16:38.650273Z","iopub.status.idle":"2025-04-03T14:16:38.964610Z","shell.execute_reply.started":"2025-04-03T14:16:38.650248Z","shell.execute_reply":"2025-04-03T14:16:38.963877Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¢ Initializing Trainer with live tracking...\nâœ… Trainer initialized!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Train Model\nprint(\"ðŸš€ Training started...\")\ntrainer.train()\nprint(\"ðŸŽ‰ Training complete!\")\n\n# Evaluate Model\nprint(\"ðŸ“Š Evaluating model performance on validation set...\")\npredictions = trainer.predict(val_dataset)\npreds = np.argmax(predictions.predictions, axis=1)\naccuracy = accuracy_score(val_labels, preds)\n\nprint(f\"âœ… Validation Accuracy: {accuracy:.4f}\")\nprint(\"ðŸ“‹ Classification Report:\")\nprint(classification_report(val_labels, preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T14:16:59.122530Z","iopub.execute_input":"2025-04-03T14:16:59.122902Z","iopub.status.idle":"2025-04-03T15:28:07.641961Z","shell.execute_reply.started":"2025-04-03T14:16:59.122873Z","shell.execute_reply":"2025-04-03T15:28:07.640520Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Training started...\n\nðŸŸ¢ Epoch 1/5 started...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5378' max='26885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 5378/26885 1:05:55 < 4:23:45, 1.36 it/s, Epoch 1/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='2689' max='2689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2689/2689 05:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"âœ… Epoch 2 completed in 3957.28 seconds.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-47c2ec88a90d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸš€ Training started...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸŽ‰ Training complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3045\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4050\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4051\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4052\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4053\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4338\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4339\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4340\u001b[0;31m             metrics = self.compute_metrics(\n\u001b[0m\u001b[1;32m   4341\u001b[0m                 \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4342\u001b[0m             )\n","\u001b[0;32m<ipython-input-11-1668a921b41c>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert logits to class predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     return {\n","\u001b[0;31mNameError\u001b[0m: name 'precision_recall_fscore_support' is not defined"],"ename":"NameError","evalue":"name 'precision_recall_fscore_support' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(val_labels, preds)\n\n# Plot confusion matrix\nplt.figure(figsize=(6,5))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Compute ROC curve and AUC\nfpr, tpr, _ = roc_curve(val_labels, preds)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(6,5))\nplt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal line for reference\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver Operating Characteristic (ROC) Curve\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:36:48.250667Z","iopub.execute_input":"2025-04-03T15:36:48.251054Z","iopub.status.idle":"2025-04-03T15:36:48.329448Z","shell.execute_reply.started":"2025-04-03T15:36:48.251028Z","shell.execute_reply":"2025-04-03T15:36:48.328103Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-1b915c00d1d3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plot confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"],"ename":"NameError","evalue":"name 'preds' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# Save the trained BioBERT model\nmodel.save_pretrained(\"./saved_biobert_model\")\ntokenizer.save_pretrained(\"./saved_biobert_model\")\n\nprint(\"âœ… Model and tokenizer saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T15:36:51.994092Z","iopub.execute_input":"2025-04-03T15:36:51.994384Z","iopub.status.idle":"2025-04-03T15:36:52.921880Z","shell.execute_reply.started":"2025-04-03T15:36:51.994362Z","shell.execute_reply":"2025-04-03T15:36:52.921111Z"}},"outputs":[{"name":"stdout","text":"âœ… Model and tokenizer saved successfully!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}